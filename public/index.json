[{"content":"Quick TL;DR By locating the kernel base address from PROCESSOR_START_BLOCK rather than scanning for KDBG, I reduced Volatility\u0026rsquo;s analysis time from ~15 seconds to about a second on a 32GB RAM sample.\nImportant: This method works only on x64 systems with no virtualization. Otherwise, we gracefully fall back to KDBG scanning.\nIntroduction and summary Volatility and Memprocfs are two tools for Memory Forensics, but they\u0026rsquo;re implemented differently. I noticed that Memprocfs parses the RAM file almost instantaneously while Volatility takes longer to analyse the file. So, I\u0026rsquo;ve conducted a test:\nI\u0026rsquo;ve extracted the RAM from my 32GB system using Winpmem. I\u0026rsquo;ve ran the pslist plugin of Volatility3 twice and started a timer each time. The first time took 51 seconds - the download of ntoskrnl symbol files took time. The second time took 15 seconds. I\u0026rsquo;ve ran Memprocfs on the same RAM file, entered the folder that show the processes list. The process list showed up immediately-after about a second. During Incident Response fast processing times of artifacts is crucial. Therefore, I decided to Reverse Engineer the tools to understand how they work and how I can improve Volatility analysis speed.\nAt first, I assumed that Memprocfs is faster because it\u0026rsquo;s built in C, meanwhile Volatility is built in Python. However, during the Reverse Engineering process I learned the algorithm used by Memprocfs and implemented it inside Volatility. After the changes I\u0026rsquo;ve made, I\u0026rsquo;ve conducted a similar test on the same aforementioned 32GB RAM file.\nThe first time took 32 seconds - all symbols of ntoskrnl were downloaded. The second time took about a second. The new algorithm is based of an undocumented structure called PROCESSOR_START_BLOCK that exists only on x64 bit systems with no virtualization and no emulation.\nAdditionally, it exists in the first 1MB of physical memory and has a well defined signature. On the other hand, the previous algorithm was based on heuristics of scanning for the KDBG structure, not necessarily existing at the beginning of the RAM file. with my new implementation, if Volatility is running against memory from x32 machine, a virtual machine or emulated machine, the algorithm will gracefully fall to the KDBG method. You can see the changes I\u0026rsquo;ve made in the merged PR inside Volatility. During the Reverse Engineering process I\u0026rsquo;ve decided to learn and understand how the algorithm works by reimplementing the process list extraction in Python. It is only for my learning purposes and should not be used in production! However, you can benefit from the newly implemented feature inside Volatility! :)\nTechnical overview During the debug process, I noticed that the \u0026quot;KDBG\u0026quot; scan takes most of the time. How do I know that? Let\u0026rsquo;s start the Reverse Engineering process.\nVolatility3 Reverse Engineering To begin analysing the memory we need to get it first. What I like to do is to run Memprocfs using the command line memprocfs -device pmem which mounts a new Virtual File System as drive M:, having the RAM file in M:\\memory.pmem. That way, I\u0026rsquo;ll be able to consult the information from live memory parsed by memprocfs. So to test Volatility3 I specified the following command line in the Pycharm debugger: python vol.py -f M:\\memory.pmem windows.pslist.PsList. After running, a lot of debugging prints started to show up in the console, indicating that the specified memory file is scanned, and it took a lot of time. So, I\u0026rsquo;ve decided to understand what is the function that is responsible for the scan by sending an interrupt Ctrl+C that will make the python console print the call stack. And indeed, you can see in the following snippet that the code is \u0026ldquo;stuck\u0026rdquo; in data = self._file.read(length).\nFollowing the call stack in the snippet, we see that a function that\u0026rsquo;s called self.determine_valid_kernel calls to valid_kernel = method(self, context, vlayer, progress_callback) which eventually calls method_kdbg_offset.\nLet\u0026rsquo;s dig in. The aforementioned function \u0026quot;determine_valid_kernel\u0026quot; iterates over a list of methods that try to detect \u0026ldquo;a valid kernel\u0026rdquo; (assigned to variable valid_kernel).\nvalid_kernel: Optional[ValidKernelType] = None for virtual_layer_name in potential_layers: vlayer = context.layers.get(virtual_layer_name, None) if isinstance(vlayer, layers.intel.Intel): for method in self.methods: valid_kernel = method(self, context, vlayer, progress_callback) if valid_kernel: break if not valid_kernel: vollog.info(\u0026#34;No suitable kernels found during pdbscan\u0026#34;) return valid_kernel ... ... ... # List of methods to be run, in order, to determine the valid kernels methods = [ method_kdbg_offset, method_module_offset, method_fixed_mapping, method_slow_scan, ] So if, for example we implement our own method to populate the variable valid_kernel, method_kdbg_offset won\u0026rsquo;t be called and the whole process should be much faster.\nWait, but wait, what should \u0026quot;valid_kernel\u0026quot; structure contain?\nIf we continue to analyze the code stack and the code statically we\u0026rsquo;ll see that determine_valid_kernel calls to method_kdbg_offset which calls to _method_offset(context, vlayer, b'KDBG', 8, progress_callback) that essentialy:\nScans for b'KDBG' bytes (_KDDEBUGGER_DATA64-\u0026gt;OwnerTag) - a process which takes a lot of time. Determines the kernel base from the structure by reading the field _KDDEBUGGER_DATA64-\u0026gt;KernBase. Calls to valid_kernel = self.check_kernel_offset(context, vlayer, address, progress_callback) where address is the previously kernel base. In the snippet below you can see the contents of the valid_kernel variable after it\u0026rsquo;s populated. In a nutshell it includes:\nthe kernel base offset in virtual memory. The name of the pdb file ntkrnlmp.pdb for the specific kernel version. The offset of the aformentioned name. The GUID that\u0026rsquo;s used to download the pdb file. So now we know what is the main \u0026ldquo;time blocker\u0026rdquo; and how theoretically we can make the program run faster. We should find the kernel base address and pass it to check_kernel_offset which initializes the variable valid_kernel. We are ready to deep dive into how Memprocfs extracts the kernel base offset.\nMemprocfs Reverse Engineering Before we list the operations that Memprocfs does to find the relevant data about the kernel, let\u0026rsquo;s explain some theory. Memprocfs relies on \u0026ldquo;the most undocumented structure\u0026rdquo; that Alex Ionescu says ([in his talk][3]) that he has seen his entire reverse engineering life - the Low Stub. The Low Stub is a tiny little piece of 16 bit code that still lives in 64 bit Windows and it\u0026rsquo;s used in two cases:\nWhen you\u0026rsquo;re booting up your processors, it starts in 16 bit Real Mode, moves to 32 bit Protected Mode by the code in Low Stub and then 64 bit Long Mode. When machine returns from sleep, it starts in 16 bit Real Mode first. The Low Stub handles the transition to Protected mode, etc.. Because of the allocation policies on modern hardware, the Low Stub is going to be at 0x1000 most of the times. On some PIC systems with a setting \u0026ldquo;Discard Low Memory\u0026rdquo; in the BIOS disabled, the Low Stub won\u0026rsquo;t be at address 0x1000, but rather 0x2000, 0x3000, etc.. The Low Stub is not only code, but actually the PROCESSOR_START_BLOCK structure, which has alot of fields, one of them called ProcessorState of type KPROCESSOR_STATE, which has Symbols and highly documented. The exciting news is the field Cr3 inside KPROCESSOR_STATE, which holds the address of the DTB (Directory Table Base) AKA, the page tables that can be used to translate virtual addresses to physical addresses.\nFor more information, here\u0026rsquo;s the talk by Alex Ionescu, start at 43:36 and here are the slides, slides 46-49. For more information about the structures mentioned above see the following reference that seems to be a leak of Windows NT. So basically the process of locating the kernel base and extracting the processes list in Memprocfs goes like this:\nIterate the first 1MB of physical memory, starting from the second page (0x1000). In each iteration, after some performed guard checks (that I document in my code), use the PROCESSOR_START_BLOCK fields offsets to extract relevant data: read the value at offset 0xa0, locating cr3 (pointing at the DTB/PML4). Additionally, in each iteration, read the value at offset 0x70, locating an address we\u0026rsquo;ll call \u0026ldquo;kernel_hint\u0026rdquo; which is an approximate location of the Kernel base. Scans for the location of ntoskrnl PE in 32mb address range beggining from \u0026ldquo;kernel_hint\u0026rdquo;, scanning in 2MB chunks. After the scan is finished, it has the offset of the kernel base.\nBut for those of you who are curious, here\u0026rsquo;s the process list location and initialization process: Extract the address of the exported function \u0026quot;PsInitialSystemProcess\u0026quot; from the kernel image in memory. The exported function contains the location of the first \u0026quot;_EPROCESS\u0026quot; object. Iterate over the list, applying fuzzing mechanisms to understand the offsets of fields even without symbols. In the snippet below, which is taken from Memprocfs, you can see the loop that iterates the first 1MB of physical memory, starting from the second page (0x1000):\nSo now that we know the algorithm of Memprocfs, let\u0026rsquo;s implement our own function.\nLet\u0026rsquo;s call it method_low_stub_offset and put it in the head of the list, the kernel image base detection should be much faster. And, it should not get to the function method_kdbg_offset which blocks, because it scans for the KDBG bytes. The new method should return a \u0026quot;valid_kernel\u0026quot; structure.\nSo essentialy, our new method will try to locate the kernel base via x64 Low Stub in lower 1MB starting from second page (4KB). If \u0026ldquo;Discard Low Memory\u0026rdquo; setting is disabled in BIOS, the Low Stub may be at the third/fourth or further pages. During the scan a few guard checks are implemented. The code is well documented so I\u0026rsquo;ll not repeat, but note how I validated the offsets of the fields. I\u0026rsquo;ve replicated the structures described in this documentation of _PROCESSOR_START_BLOCK and wrote the following code that prints the offset of the given field within the structure:\nvoid print_diff(ULONG64 field_address, ULONG64 base_address) { printf(\u0026#34;%d:%x\\n\u0026#34;, field_address - base_address, field_address - base_address); } I\u0026rsquo;ve put all the constant offsets and signatures well documented here.\nBasically the algorithm as the same as previously mentioned. The implemented guard statements are similar to those in Memprocfs except the third:\nThe first 8 bytes of PROCESSOR_START_BLOCK \u0026amp; 0xFFFFFFFFFFFF00FF expected signature for validation is checked: 0x00000001000600E9. It\u0026rsquo;s constructed from: a. The block starts with a jmp instruction to the end of the block:\nPROCESSOR_START_BLOCK-\u0026gt;Jmp-\u0026gt;OpCode = 0xe9 (jmp opcode), of type UCHAR PROCESSOR_START_BLOCK-\u0026gt;Jmp-\u0026gt;Offset = 0x6XX, of type USHORT b. A Completion flag is set to non-zero when the target processor has started: PROCESSOR_START_BLOCK-\u0026gt;CompletionFlag = 0x1, of type ULONG\nCompare previously observed valid page table address that\u0026rsquo;s stored in vlayer._initial_entry with PROCESSOR_START_BLOCK-\u0026gt;ProcessorState-\u0026gt;SpecialRegisters-\u0026gt;Cr3 which was observed to be an invalid page address, so add 1 (to make it valid too).\nPROCESSOR_START_BLOCK-\u0026gt;LmTarget \u0026amp; 0x3 should be 0, meaning the page entry for the kernel entry should be invalid(1st bit of address) and not readable/writable(2nd bit of address).\nClosing Thoughts Hope you enjoyed reading this as much as I enjoyed implementing it and the community will benefit from this contribution. Special thanks to the creators and maintainers of the Volatility project and to Ulf Frisk, the creator of Memprocfs.\nAlways ask yourself how you can make things run better and be curious how things work, that\u0026rsquo;s how I learned a lot from this work.\nIf you have any questions feel free to reach me at danieldavidov555@proton.me.\n","permalink":"http://localhost:1313/posts/making-volatility-15x-faster-lessons-from-reverse-engineering-windows-internals/","summary":"\u003ch2 id=\"quick-tldr\"\u003eQuick TL;DR\u003c/h2\u003e\n\u003cp\u003eBy locating the kernel base address from \u003ccode\u003ePROCESSOR_START_BLOCK\u003c/code\u003e rather than scanning for \u003ccode\u003eKDBG\u003c/code\u003e, I reduced Volatility\u0026rsquo;s analysis time from \u003cstrong\u003e~15 seconds to about a second\u003c/strong\u003e on a 32GB RAM sample.\u003c/p\u003e\n\u003cp\u003eImportant: This method works only on x64 systems with no virtualization. Otherwise, we gracefully fall back to \u003ccode\u003eKDBG\u003c/code\u003e scanning.\u003c/p\u003e\n\u003ch2 id=\"introduction-and-summary\"\u003eIntroduction and summary\u003c/h2\u003e\n\u003cp\u003eVolatility and Memprocfs are two tools for Memory Forensics, but they\u0026rsquo;re implemented differently.\nI noticed that Memprocfs parses the RAM file almost instantaneously while Volatility takes longer to analyse the file.\nSo, I\u0026rsquo;ve conducted a test:\u003c/p\u003e","title":"Making Volatility 15x Faster: Lessons from Reverse Engineering Windows Internals"}]